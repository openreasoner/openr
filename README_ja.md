<div id="top"></div>
<!--
*** Thanks for checking out the Best-README-Template. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag "enhancement".
*** Don't forget to give the project a star!
*** Thanks again! Now go create something AMAZING! :D
-->

<!-- PROJECT SHIELDS -->

<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

<!-- 
***[![MIT License][license-shield]][license-url]
-->

<!-- PROJECT LOGO -->

<br />
<div align="center">
  <a href="https://github.com/openreasoner/openr/">
    <img src="figure/openr_logo.png" alt="Logo" width="200">
  </a>
  
<h1 align="center" style="font-size: 30px;"><strong><em>OpenR</em></strong>: å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹é«˜åº¦ãªæ¨è«–ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</h1>
<p align="center">
    <a href="https://arxiv.org/abs/2410.09671">è«–æ–‡</a>
    Â·
    <a href="https://github.com/openreasoner/openr/blob/main/reports/Tutorial-LLM-Reasoning-Wang.pdf">ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«</a>
    Â·
    <a href="https://github.com/openreasoner/openr">ã‚³ãƒ¼ãƒ‰</a>
    Â·
    <a href="https://openreasoner.github.io/">ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a>
    Â·
    <a href="https://huggingface.co/datasets/openreasoner/MATH-APS">ãƒ‡ãƒ¼ã‚¿</a>
    Â·
    <a href="https://huggingface.co/openreasoner/Math-psa">ãƒ¢ãƒ‡ãƒ«</a>
    Â·
    <a href="https://github.com/openreasoner/openr/issues">å•é¡Œ</a>
  </p>
    <p align="center">
     [ <a href="https://github.com/openreasoner/openr/blob/main/README.md">English</a> ][ <a href="https://github.com/openreasoner/openr/blob/main/README_zh.md">ä¸­æ–‡</a> ][ <a href="https://github.com/openreasoner/openr/blob/main/README_ja.md">æ—¥æœ¬èª</a> ]
    </p>
</div>

---
[![GitHub contributors](https://img.shields.io/github/contributors/openreasoner/openr)][contributors-url]
[![arXiv](https://img.shields.io/badge/ArXiv-2410.09671-b31b1b.svg)](https://arxiv.org/pdf/2410.09671)
![GitHub License](https://img.shields.io/github/license/openreasoner/openr)
[![GitHub Issues or Pull Requests](https://img.shields.io/github/issues/openreasoner/openr)][issues-url]
[![GitHub forks](https://img.shields.io/github/forks/openreasoner/openr)][forks-url]
[![GitHub Repo stars](https://img.shields.io/github/stars/openreasoner/openr)][stars-url]
[![HuggingFace Dataset](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000)](https://huggingface.co/openreasoner)
[![X](https://img.shields.io/badge/openreasoner-%23000000.svg?logo=X&logoColor=white)](https://x.com/openreasoner)
[![WeChat](https://img.shields.io/badge/WeChat_Group-07C160?logo=wechat&logoColor=white)](#community)


<!-- TABLE OF CONTENTS -->

<details>
  <summary><span style="font-size: 1.5em;"><strong>ç›®æ¬¡</strong> ğŸ“– </span></summary>
  <ol>
    <li><a href="#ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ›´æ–°">ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ›´æ–°</a></li>
    <li><a href="#æ©Ÿèƒ½">æ©Ÿèƒ½</a></li>
    <li><a href="#ãƒ—ãƒ­ãƒƒãƒˆ">ãƒ—ãƒ­ãƒƒãƒˆ</a></li>
    <li><a href="#æä¾›ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«">æä¾›ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«</a></li>
    <li>
      <a href="#å§‹ã‚ã«">å§‹ã‚ã«</a>
      <ul>
        <li><a href="#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«">ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</a></li>
        <li><a href="#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ">ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ</a></li>
      </ul>
    </li>
    <li><a href="#ä½¿ç”¨æ³•">ä½¿ç”¨æ³•</a></li>
    <li><a href="#å‚åŠ ">å‚åŠ </a></li>
    <li><a href="#é€£çµ¡å…ˆ">é€£çµ¡å…ˆ</a></li>
    <li><a href="#å¿œç­”ä¾‹">å¿œç­”ä¾‹</a></li>
    <li><a href="#ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£">ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£</a></li>
    <li><a href="#å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</a></li>
  </ol>

</details>

<!-- News and Updates -->

## ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ›´æ–°
- **[2024å¹´10æœˆ24æ—¥]** ***OpenR*** ã¯ **MCTS** æ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã—ãŸ ([#24](https://github.com/openreasoner/openr/pull/24))! ğŸŒ²
- **[2024å¹´10æœˆ15æ—¥]** ç§ãŸã¡ã®ãƒ¬ãƒãƒ¼ãƒˆãŒ [**Arxiv**](https://arxiv.org/abs/2410.09671) ã«æ²è¼‰ã•ã‚Œã¾ã—ãŸ! 
- **[2024å¹´10æœˆ12æ—¥]** ***OpenR*** ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸ! ğŸš€ 


## æ©Ÿèƒ½

<p align="center">
  <img src="./figure/logo_text.png" alt="Description" style="width: 300px; margin-left: 50px; float: right;">
</p>

<div style="display: flex; align-items: center;">
<ul style="list-style-type: none; padding: 0;">
    <li><strong>âœ… ãƒ—ãƒ­ã‚»ã‚¹ç›£ç£ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</strong></li>
    <li><strong>âœ… ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒªã‚·ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°</strong></li>
    <li><strong>âœ… ç”Ÿæˆçš„ãŠã‚ˆã³è­˜åˆ¥çš„PRMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°</strong></li>
    <li><strong>âœ… è¤‡æ•°ã®æ¤œç´¢æˆ¦ç•¥</strong></li>
    <li><strong>âœ… ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡</strong></li>
</ul>
</div>

## ãƒ—ãƒ­ãƒƒãƒˆ

<p align="center">
  <img src="./figure/compare_prm_by_boN.png" alt="PRM_Results" width="45%" />
  <img src="./figure/MATH_subsampled.png" alt="Inference_Results" width="45%" />
</p>

## æä¾›ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«

[//]: # ([PRM800K]&#40;https://github.com/openai/prm800k&#41; &#40;Process Supervision Dataset&#41;)

[MATH-APS](https://huggingface.co/datasets/mengfang/MATH-APS) (ç§ãŸã¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)

[MATH-psa](https://huggingface.co/openreasoner/Math-psa) (ç§ãŸã¡ã®ãƒ—ãƒ­ã‚»ã‚¹å ±é…¬ãƒ¢ãƒ‡ãƒ«)

## å§‹ã‚ã«


### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```
conda create -n open_reasoner python=3.10
conda activate open_reasoner
pip install -r requirements.txt
pip3 install  "fschat[model_worker,webui]"
pip install -U pydantic
cd envs/MATH/latex2sympy
pip install -e .
cd -
```


### ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€å¿…è¦ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã™ã¹ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š

- `Qwen2.5-Math-1.5B-Instruct`, `Qwen2.5-Math-7B-Instruct`
- `peiyi9979/mistral-7b-sft`
- `peiyi9979/math-shepherd-mistral-7b-prm`

ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€[Hugging Faceãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/hub/models-downloading)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¨­å®šã«å¾“ã£ã¦ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒå„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚


### ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€`reason/llm_service/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ä»¥ä¸‹ã®å¤‰æ•°ã‚’å¤‰æ›´ã—ã¦ã€ä½¿ç”¨ã™ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š

- `$MODEL_BASE`: ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚
- `$POLICY_MODEL_NAME`: ä½¿ç”¨ã™ã‚‹ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®åå‰ã‚’è¨­å®šã—ã¾ã™ã€‚
- `$VALUE_MODEL_NAME`: ä½¿ç”¨ã™ã‚‹ãƒãƒªãƒ¥ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®åå‰ã‚’è¨­å®šã—ã¾ã™ã€‚
- `$NUM_LM_WORKER`: èµ·å‹•ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚
- `$NUM_RM_WORKER`: èµ·å‹•ã™ã‚‹å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMï¼‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

æ¬¡ã«ã€ç•°ãªã‚‹æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

#### LM & RM ã‚µãƒ¼ãƒ“ã‚¹ã®é–‹å§‹

ä¾‹ãˆã°ã€Math Shepherdãƒ¢ãƒ‡ãƒ«ã®LMã¨RMã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š



```bash
sh reason/llm_service/create_service_math_shepherd.sh
```

ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ï¼š
```bash
tmux kill-session -t {Your Session Name} # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯`FastChat`
```

## ä½¿ç”¨æ³•

#### æ¨è«–ã®å®Ÿè¡Œ


âš ï¸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ`--LM`, `--RM`ï¼‰ãŒã€ä¿ç•™ä¸­ã®ãƒ¯ãƒ¼ã‚«ãƒ¼å†…ã®å¤‰æ•°ï¼ˆ`$POLICY_MODEL_NAME`, `$VALUE_MODEL_NAME`ï¼‰ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼



```bash
export PYTHONPATH=$(pwd)
sh scripts/eval/cot_greedy.sh

# Method: cot. Average result: ({'majority_vote': 0.734, 'total_completion_tokens': 559.13},)

sh scripts/eval/cot_rerank.sh

# Method: best_of_n. Average result: ({'majority_vote': 0.782, 
#                                       'prm_min_max': 0.772, 
#                                       'prm_min_vote': 0.792, 
#                                       'prm_last_max': 0.776, 
#                                       'prm_last_vote': 0.792, 
#                                       'total_completion_tokens': 4431.268},)

sh scripts/eval/beam_search.sh

# Method: beam_search. Average result: ({'majority_vote': 0.74, 'total_completion_tokens': 2350.492},)

sh scripts/eval/vanila_mcts.sh

```

#### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ

âš ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€`train/mat/scripts/train_llm.sh`ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®`$dataset_path`, `$model_name_or_path`ãŠã‚ˆã³`$prm_name_or_path`ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

```bash
cd train/mat/scripts
bash train_llm.sh
```

#### PRMå­¦ç¿’ã®å®Ÿè¡Œ

```bash
cd prm/code

\\ single gpu
python finetune_qwen_single_gpu.py --model_path $YOUR_MODEL_PATH \
                                   --train_data_path $TRAIN_DATA_PATH \
                                   --test_data_path $TEST_DATA_PATH


\\ multi gpu
torchrun --nproc_per_node=2 finetune_qwen.py --model_path $YOUR_MODEL_PATH \
                                             --data_path $YOUR_DATA_FOLDER_PATH \
                                             --datasets both \
```

## å‚åŠ 

> ã™ã¹ã¦ã®è²¢çŒ®ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã¨ã£ã¦ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚

***OpenR*** ã«ã”é–¢å¿ƒã‚’ãŠå¯„ã›ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ğŸ¥° ç§ãŸã¡ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æ·±ãã‚³ãƒŸãƒƒãƒˆã—ã¦ãŠã‚Šã€çš†ã•ã‚“ã®è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ã€‚ã‚ãªãŸã®åŠªåŠ›ã¯å¤§å°ã«ã‹ã‹ã‚ã‚‰ãšã€ç§ãŸã¡ã®æˆé•·ã¨æ”¹å–„ã«å½¹ç«‹ã¡ã¾ã™ã€‚è²¢çŒ®ã¯ã‚³ãƒ¼ãƒ‰ã«é™ã‚‰ãšã€è³ªå•ã«ç­”ãˆãŸã‚Šã€ä»–ã®äººã‚’åŠ©ã‘ãŸã‚Šã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ”¹å–„ã—ãŸã‚Šã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å…±æœ‰ã—ãŸã‚Šã™ã‚‹ã“ã¨ã‚‚åŒæ§˜ã«å½±éŸ¿åŠ›ãŒã‚ã‚Šã¾ã™ã€‚

[è²¢çŒ®ã‚¬ã‚¤ãƒ‰](CONTRIBUTING.md) ã‚’ã”è¦§ãã ã•ã„ï¼ 

### å°†æ¥ã®è¨ˆç”»

- RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œç´¢æˆ¦ç•¥ã«é–¢ã™ã‚‹ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªè©•ä¾¡ã‚’è¿½åŠ 

- Prove-Verifierãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚’æ‹¡å¤§

- è‡ªå·±æ”¹å–„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚µãƒãƒ¼ãƒˆ

<!-- CONTACT -->

## é€£çµ¡å…ˆ

***OpenR*** ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ä»¥ä¸‹ã®ãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ç¶­æŒã•ã‚Œã¦ã„ã¾ã™ï¼š

- **Openreasoner Team** (openreasoner@gmail.com)

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

***OpenR*** ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## å¼•ç”¨

ç§ãŸã¡ã®ãƒªã‚½ãƒ¼ã‚¹ãŒå½¹ç«‹ã¤ã¨æ„Ÿã˜ãŸå ´åˆã¯ã€ç§ãŸã¡ã®è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```
@article{wang2024openr,
  title={OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models},
  author={Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others},
  journal={arXiv preprint arXiv:2410.09671},
  year={2024}
}
```
ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼

## å¿œç­”ä¾‹

### PRMã®æ¯”è¼ƒã€Math-psaï¼ˆç§ãŸã¡ã®ã‚‚ã®ï¼‰å¯¾Math-Shepherd 

<p align="center">
  <img src="./figure/QA/QA1.png" alt="QA 1" width="49%" />
  <img src="./figure/QA/QA2.png" alt="QA 2" width="49%" />
</p>


### RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ­£å½“åŒ–

<p align="center">
  <img src="./figure/QA/QA3.png" alt="QA 3" width="49%" />
  <img src="./figure/QA/QA4.png" alt="QA 4" width="49%" />
</p>

### ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã®æ¢ç´¢

<p align="center">
  <img src="./figure/QA/QA5.png" alt="QA 5" width="70%" />
  <img src="./figure/QA/QA6.png" alt="QA 6" width="70%" />
  <img src="./figure/QA/QA7.png" alt="QA 7" width="70%" />
</p>


## ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

**WeChat**:

<img src="./figure/wechat_qrcode.jpg" width="30%" />



## å‚è€ƒæ–‡çŒ®

### æ¨è«–æ™‚ã®è¨ˆç®—
[1] [Alphazero-like tree-search can guide large language model decoding and training.](https://arxiv.org/pdf/2309.17179)

[2] [Reasoning with language model is planning with world model.](https://arxiv.org/pdf/2305.14992)

[3] [Scaling LLM test-time compute optimally can be more effective than scaling model parameters](https://arxiv.org/pdf/2408.03314?)

[4] [Think before you speak: Training language models with pause tokens](https://arxiv.org/pdf/2310.02226)


### çµæœç›£ç£ã‹ã‚‰ãƒ—ãƒ­ã‚»ã‚¹ç›£ç£ã¸

[1] [Training verifiers to solve math word problems](https://arxiv.org/pdf/2110.14168)

[2] [Solving math word problems with process-and outcome-based feedback](https://arxiv.org/pdf/2211.14275)

[3] [Letâ€™s verify step by step](https://arxiv.org/pdf/2305.20050)

[4] [Making large language models better reasoners with step-aware verifier](https://arxiv.org/pdf/2206.02336)

[5] [Ovm, outcome-supervised value models for planning in
mathematical reasoning](https://aclanthology.org/2024.findings-naacl.55.pdf)

[6] [Generative verifiers: Reward modeling as next-token prediction](https://arxiv.org/pdf/2408.15240)

### ãƒ‡ãƒ¼ã‚¿å–å¾—

[1] [Star: Bootstrapping reasoning with reasoning](https://proceedings.neurips.cc/paper_files/paper/2022/file/639a9a172c044fbb64175b5fad42e9a5-Paper-Conference.pdf)

[2] [Quiet-star: Language models can teach themselves to think before speaking](https://arxiv.org/pdf/2403.09629)

[3] [Improve mathematical reasoning in language models by automated
process supervision](https://arxiv.org/pdf/2406.06592)

[4] [Shepherd: A critic for language model generation](https://arxiv.org/abs/2308.04592)

[5] [Math-shepherd: Verify and reinforce llms step-by-step without human annotations](https://aclanthology.org/2024.acl-long.510.pdf)

<!-- MARKDOWN LINKS & IMAGES -->

<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/openreasoner/openr.svg?style=for-the-badge
[contributors-url]: https://github.com/openreasoner/openr/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/openreasoner/openr.svg?style=for-the-badge
[forks-url]: https://github.com/openreasoner/openr/network/members
[stars-shield]: https://img.shields.io/github/stars/openreasoner/openr.svg?style=for-the-badge
[stars-url]: https://github.com/openreasoner/openr/stargazers
[issues-shield]: https://img.shields.io/github/issues/openreasoner/openr.svg?style=for-the-badge
[issues-url]: https://github.com/openreasoner/openr/issues

[license-shield]: https://img.shields.io/github/license/openreasoner/openr.svg?style=for-the-badge
[license-url]: https://github.com/openreasoner/openr/blob/main/LICENSE.txt
